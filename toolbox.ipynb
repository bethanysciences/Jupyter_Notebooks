{
 "cells": [
  {
   "source": [
    "# datetime Functions\n",
    "```\n",
    "date.year, date.month, date.day\n",
    "date.strftime(format) Return a string representing the date, controlled by an explicit format string. Format codes referring to hours, minutes or seconds will see 0 values.\n",
    "\n",
    "%a Weekday as locale’s abbreviated name.\n",
    "%A Weekday as locale’s full name.\n",
    "%w Weekday as a decimal number, where 0 is Sunday and 6 is Saturday.\n",
    "%d Day of the month as a zero-padded decimal number.\n",
    "%b Month as locale’s abbreviated name.\n",
    "%B Month as locale’s full name.\n",
    "%m Month as a zero-padded decimal number.\n",
    "%y Year without century as a zero-padded decimal number.\n",
    "%Y Year with century as a decimal number.\n",
    "%H Hour (24-hour clock) as a zero-padded decimal number.\n",
    "%I Hour (12-hour clock) as a zero-padded decimal number.\n",
    "%p Locale’s equivalent of either AM or PM.\n",
    "%M Minute as a zero-padded decimal number.\n",
    "%S Second as a zero-padded decimal number.\n",
    "%f Microsecond as a decimal number, zero-padded on the left.\n",
    "%z UTC offset in the form +HHMM or -HHMM (empty string if the the object is naive).\n",
    "%Z Time zone name (empty string if the object is naive).\n",
    "%j Day of the year as a zero-padded decimal number.\n",
    "%U Week number of the year (Sunday as the first day of the week) as a zero padded decimal number. All days in a new year preceding the first Sunday are considered to be in week 0.\n",
    "%W Week number of the year (Monday as the first day of the week) as a decimal number. All days in a new year preceding the first Monday are considered to be in week 0.\n",
    "%c Locale’s appropriate date and time representation.\n",
    "%x Locale’s appropriate date representation.\n",
    "%X Locale’s appropriate time representation.\n",
    "%% literal '%' character.\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "15:30:18\n15:30:18\n15:30:18\nI'm working...\n15:30:19\n15:30:19\n15:30:19\nI'm working...\n15:30:20\n15:30:20\n15:30:20\nI'm working...\n15:30:21\n15:30:21\n15:30:21\nI'm working...\n15:30:22\n15:30:22\n15:30:22\nI'm working...\n15:30:23\n15:30:23\n15:30:23\nI'm working...\n15:30:24\n15:30:24\n15:30:24\nI'm working...\n15:30:25\n15:30:25\n15:30:25\nI'm working...\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9b57e2af98dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/schedule/__init__.py\u001b[0m in \u001b[0;36mrun_pending\u001b[0;34m()\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdefault\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mdefault_scheduler\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \"\"\"\n\u001b[0;32m--> 563\u001b[0;31m     \u001b[0mdefault_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/schedule/__init__.py\u001b[0m in \u001b[0;36mrun_pending\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[1;32m     92\u001b[0m         \u001b[0mrunnable_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunnable_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/schedule/__init__.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mbetween\u001b[0m \u001b[0mbut\u001b[0m \u001b[0monly\u001b[0m \u001b[0monce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mrunnable_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunnable_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/schedule/__init__.py\u001b[0m in \u001b[0;36mshould_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mjob\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mrun\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \"\"\"\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime, date, time, timezone\n",
    "import schedule\n",
    "def clock():\n",
    "    dt = datetime.now()\n",
    "    clock = '%02d:%02d:%02d' % (dt.hour, dt.minute, dt.second)\n",
    "    print(clock)\n",
    "\n",
    "clock()\n",
    "\n",
    "schedule.every(1).seconds.do(clock)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "\n",
    "df['Date Time'] = pd.to_datetime(df['Date Time'])\n",
    "mask = (df['Date Time'] > datetime.now())\n",
    "df = df.loc[mask]\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import schedule\n",
    "import time\n",
    "\n",
    "def job():\n",
    "    print(\"I'm working...\")\n",
    "\n",
    "schedule.every(1).seconds.do(job)\n",
    "# schedule.every().hour.do(job)\n",
    "# schedule.every().day.at(\"10:30\").do(job)\n",
    "# schedule.every(5).to(10).minutes.do(job)\n",
    "# schedule.every().monday.do(job)\n",
    "# schedule.every().wednesday.at(\"13:15\").do(job)\n",
    "# schedule.every().minute.at(\":17\").do(job)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T02:34:15.217551Z",
     "start_time": "2019-08-18T02:34:15.186138Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://vishalmnemonic.github.io/DC6/\n",
    "\n",
    "import io\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,9))\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from collections import OrderedDict\n",
    "import IPython\n",
    "import pytz\n",
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "!python3 --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vader Sentiment\n",
    "\n",
    "```python\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer  \n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    print(\"{:-<40} {}\".format(sentence, str(score)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoPandas\n",
    "<a href=\"https://geopandas.org\"><img src=\"img/l_geopandas.png\" style=\"float: right;\"></a>\n",
    "  \n",
    "```python\n",
    "!pip3 install geopandas\n",
    "import geopandas as gpd\n",
    "geo_df = geopandas.read_file(\"data/maps/usgeojson/gz_2010_us_040_00_5m.json\")\n",
    "geo_df.head()\n",
    "geo_df = gpd.read_file(\"data/maps/states_21basic/states.shp\")\n",
    "geo_df[\"STATE_FIPS\"] = geo_df[\"STATE_FIPS\"].astype(np.int64)\n",
    "geo_df.head()\n",
    "geo_df.dtypes\n",
    "geo_df.plot()\n",
    "df = pd.read_csv(\"data/uspop-nst-2018.csv\", header=0)\n",
    "df = df[['STATE_FIPS','POP_2018']]\n",
    "merged = geo_df.join(df.set_index(\"STATE_FIPS\"), on=\"STATE_FIPS\")\n",
    "merged.head()\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "divider = make_axes_locatable(ax)\n",
    "merged.plot(column='POP_2018',\n",
    "           ax=ax,\n",
    "           legend=True,\n",
    "           legend_kwds={'label': \"Population by State (m)\",\n",
    "                        'orientation': \"horizontal\"})\n",
    "merged.plot(column='POP_2018');\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "merged.plot(column='POP_2018', ax=ax, legend=True, cax=cax)\n",
    "\n",
    "fig.savefig(\"leaddistribution.png\", dpi=300)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel<a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html\"><img src=\"img/l_excel.png\" style=\"float: right;\"></a>     \n",
    "  \n",
    "```python\n",
    "import pandas as pd\n",
    "url ='http://s3.amazonaws.com/assets.datacamp.com/course/importing_data_into_r/latitude.xls'\n",
    "xl = pd.read_excel(url,sheetname=None)\n",
    "print(xl.keys())\n",
    "print(xl['1700'].head())\n",
    "\n",
    "\n",
    "!pip install xlrd\n",
    "import xlrd\n",
    "xlsx = pd.ExcelFile('examples/ex1.xlsx')\n",
    "df = pd.read_excel('examples/ex1.xlsx', 'Sheet1')\n",
    "writer = pd.ExcelWriter('examples/ex2.xlsx')\n",
    "frame.to_excel(writer, 'Sheet1')\n",
    "df.to_excel('examples/ex2.xlsx')\n",
    "df.to_excel(writer, 'Sheet1')\n",
    "writer.save()\n",
    "!rm examples/ex2.xlsx\n",
    "```\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BeautyfulSoup4\n",
    "<a href=\"https://www.crummy.com/software/BeautifulSoup/\"><img src=\"img/l_beautsoup4.jpg\" style=\"width: 50px; float: right;\"></a>\n",
    "\n",
    "```python\n",
    "!pip3 install BeautifulSoup4\n",
    "\n",
    "Scape all URL's off a page\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://www.python.org/~guido/'\n",
    "r = requests.get(url)\n",
    "html_doc = r.text\n",
    "soup = BeautifulSoup(html_doc)\n",
    "print(soup.title)\n",
    "a_tags = soup.find_all('a')\n",
    "for link in a_tags:\n",
    "    print(link.get('href'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# Specify url: url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "# Prettify the BeautifulSoup object: pretty_soup\n",
    "pretty_soup =  soup.prettify()\n",
    "# Print the response\n",
    "print(pretty_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Import package\n",
    "import requests\n",
    "# Specify the url: url\n",
    "url = \"http://www.datacamp.com/teach/documentation\"\n",
    "# Packages the request, send the request and catch the response: r\n",
    "r= requests.get(url)\n",
    "# Extract the response: text\n",
    "text = r.text\n",
    "# Print the html\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# Specify url: url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "# Prettify the BeautifulSoup object: pretty_soup\n",
    "pretty_soup =  soup.prettify()\n",
    "# Print the response\n",
    "print(pretty_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from urllib.request import urlopen, Request\n",
    "# Specify the url\n",
    "url = \"http://www.datacamp.com/teach/documentation\"\n",
    "# This packages the request\n",
    "request = Request(url)\n",
    "# Sends the request and catches the response: response\n",
    "response = urlopen(request)\n",
    "# Extract the response: html\n",
    "html = response.read()\n",
    "# Print the html\n",
    "print(html)\n",
    "# Be polite and close the response!\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from urllib.request import urlopen, Request\n",
    "# Specify the url\n",
    "url = \"http://www.datacamp.com/teach/documentation\"\n",
    "# This packages the request: request\n",
    "request=Request(url)\n",
    "# Sends the request and catches the response: response\n",
    "response = urlopen(request)\n",
    "# Print the datatype of response\n",
    "print(type(response))\n",
    "# Be polite and close the response!\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapy\n",
    "<a href=\"https://scrapy.org\"><img src=\"img/l_scrapy.png\" style=\"width: 200px; float: right;\"></a>  \n",
    "\n",
    "  \n",
    "```python\n",
    "!pip3 install scrapy\n",
    "!pip3 install json\n",
    "!pip3 install logging\n",
    "\n",
    "import pandas as pd\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import json\n",
    "import logging\n",
    "class JsonWriterPipeline(object):\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('venues.jl', 'w')\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"venues\"\n",
    "    start_urls = ['https://www.cvent.com/venues/results/United%20States?']\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1},       # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                       # Used for pipeline 2\n",
    "        'FEED_URI': 'venues.json'                                   # Used for pipeline 2\n",
    "    }\n",
    "    def parse(self, response):\n",
    "        for venue in response.css('div.quote'):\n",
    "            yield {\n",
    "                'name': quote.css('span.text::text').extract_first(),           \n",
    "data-cvent-id=\"searchResult-mainContent-mainResults-venueListContainer-ul-li-0-venueCard-link-wrapper-venueInfoWrapper-venueName\n",
    "                'author': quote.css('span small::text').extract_first(),\n",
    "                'tags': quote.css('div.tags a.tag::text').extract(),\n",
    "            }\n",
    "        NEXT_PAGE_SELECTOR = '.next a ::attr(href)'\n",
    "        next_page = response.css(NEXT_PAGE_SELECTOR).extract_first()\n",
    "        if next_page:\n",
    "            yield scrapy.Request(\n",
    "                response.urljoin(next_page),\n",
    "                callback=self.parse\n",
    "            )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bokah\n",
    "<a href=\"https://www.mysql.com/products/connector/\"><img src=\"img/l_bokeh.png\" style=\"float: right;\"></a>  \n",
    "  \n",
    "```python\n",
    "!pip3 install bokeh\n",
    "!pip3 install hvplot\n",
    "import bokeh  \n",
    "from bokeh.io import output_notebook, output_file, show, push_notebook\n",
    "from bokeh.plotting import *\n",
    "from bokeh.models import ColumnDataSource, HoverTool, CategoricalColorMapper\n",
    "from bokeh.layouts import row, column, gridplot, widgetbox\n",
    "from bokeh.models.widgets import Tabs, Panel\n",
    "from bokeh.transform import factor_cmap\n",
    "import hvplot as hv\n",
    "import hvplot.pandas  \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MySQL\n",
    "<a href=\"https://www.mysql.com/products/connector/\"><img src=\"img/l_mysql.png\" style=\"float: right;\"></a>   \n",
    "  \n",
    "```python\n",
    "!pip install mysql-connector-python\n",
    "import mysql.connector\n",
    "config = {\n",
    "    'host': 'rpsmithii.mysql.pythonanywhere-services.com',\n",
    "    'database': 'rpsmithii$weight','user': 'rpsmithii',\n",
    "    'password': 'Home@Call4','port': '3306'}\n",
    "db = mysql.connector.connect(**config)\n",
    "cur = db.cursor()\n",
    "cur.execute(\"SELECT dt, wht FROM weight WHERE wht > 10\")\n",
    "table = pd.DataFrame(cur.fetchall())\n",
    "table.columns = cur.column_names\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "<a href=\"https://pandas.pydata.org\"><img src=\"img/l_pandas.png\" style=\"float: right;\"></a> \n",
    "  \n",
    "```python\n",
    "!pip3 install pandas\n",
    "import pandas as pd                     \n",
    "```\n",
    "\n",
    "### csv methods\n",
    "```python\n",
    "df = pd.read_csv('data/hosp.csv', index_col='Target?', dtype={'user_id': int})\n",
    "with open('csvfile.csv', 'w') as csvfile: f = csv.writer(csvfile) f.writerows(items)   # write to csv file\n",
    "```\n",
    "\n",
    "### attributes\n",
    "```python\n",
    "pd.info()                               # data types and specs\n",
    "pd.shape                                # dimensions (tuple)\n",
    "pd.describe()                           # shows a quick statistic data summary\n",
    "pd.dtypes                               # column labels & data types\n",
    "pd.index                                # index (row labels)\n",
    "pd.head(n)                              # return first n rows\n",
    "pd.tail(n)                              # return last n rows    \n",
    "pd.columns                              # column labels\n",
    "pd.values                               # Numpy representation\n",
    "pd.axes                                 # list axes\n",
    "pd.size                                 # number (int) elements\n",
    "pd.memory_usage([index, deep])          # each column memory (bytes)\n",
    "```\n",
    "\n",
    "### transforms\n",
    "```python\n",
    "pd.between_time(start_time, end_time)\t# select range\n",
    "pd.set_index()                          # set index using existing columns\n",
    "pd.['col0'].astype(str)                 # change data type\n",
    "df = pd.drop(\"del\", axis=0)             # delete all rows with label \"del\"\n",
    "df = pd.concat([df01, df02, df03])      # combine dataframes\n",
    "pd.is_copy                              # return copy\n",
    "pd.empty                                # empty\n",
    "df = df0.drop(columns=[' X', ' N'])     # drop columns\n",
    "df = df0.sort_values(by='column')       # sort\n",
    "```\n",
    "\n",
    "### [plots](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html)\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.rcParams[\"figure.figsize\"] = [16,9]\n",
    "df.plot.area([x, y])                    # stacked area plot\n",
    "df.plot.bar([x, y])                     # vertical bar plot\n",
    "df.plot.barh([x, y])                    # horizontal bar plot\n",
    "df.plot.box([by])                       # box plot\n",
    "df.boxplot([column, by, ax, …])         # box plot from columns\n",
    "df.plot.hist([by, bins])                # histogram of columns\n",
    "df.hist([column, by, grid, …])          # histogram\n",
    "df.plot.line([x, y])                    # columns as lines\n",
    "df.plot.pie([y])                        # pie plot\n",
    "df.plot.scatter(x, y[, s, c])           # scatter plot\n",
    "df.plot(legend=False)\n",
    "df.plot(xlabel=\"new x\", ylabel=\"new y\")\n",
    "ts.plot(logy=True)                      # log-scale\n",
    "df['B'].plot(secondary_y=True, style='g') # secondary axis\n",
    "df['A'].plot(x_compat=True)             # compa\n",
    "df.plot.line()\n",
    "with pd.plotting.plot_params.use('x_compat', True):\n",
    "    df[' Air Temperature'].plot(color='b')\n",
    "    df[' Water Temperature'].plot(color='g')\n",
    "plt.rcParams[\"figure.figsize\"] = [16,9]\n",
    "dfa.plot.line()\n",
    "dfw.plot.line()\n",
    "```\n",
    "\n",
    "### lookup()\n",
    "Extract a set of values given a sequence of row labels and column labels return **NumPy array**\n",
    "\n",
    "```python\n",
    "DataFrame.lookup(list(range(0, 10, 2)), ['B', 'C', 'A', 'B', 'D'])\n",
    "```\n",
    "\n",
    "### query()\n",
    "\n",
    "column b has values between column a and c values\n",
    "```python\n",
    "DataFrame.query('(a < b) & (b < c)')\n",
    "index = pd.MultiIndex.from_arrays([colors, foods], names=['color', 'food'])\n",
    "```\n",
    "\n",
    "columns a and \"b\" have overlapping values\n",
    "```python\n",
    "DataFrame.query('a in b')\n",
    "```\n",
    "\n",
    "columns a and b have overlapping values and col c's values are less than col d's\n",
    "```python\n",
    "DataFrame.query('a in b and c < d')\n",
    "```\n",
    "\n",
    "Comparing a list of values to a column using ==/!= works similarly to in/not in.\n",
    "```python\n",
    "DataFrame.query('b == [\"a\", \"b\", \"c\"]')\n",
    "```\n",
    "\n",
    "select rows with index values 'Andrade' + 'Veness' with columns fr 'city' to 'email'  \n",
    "```python\n",
    "nDataFrame.loc[['Andrade', 'Veness'], 'city':'email']\n",
    "```  \n",
    "  \n",
    "select same rows, with just 'first_name', 'address' and 'city' columns  \n",
    "```python\n",
    "DataFrame.loc['Andrade':'Veness', ['first_name', 'address', 'city']]\n",
    "```  \n",
    "  \n",
    "select rows with _first name_ Antonio and _columns_ 'city' to 'email'  \n",
    "  \n",
    "```python\n",
    "DataFrame.loc[DataFrame['first_name'] == 'Antonio', 'city':'email']\n",
    "```  \n",
    "  \n",
    "Select rows where email column ends w/ 'hotmail.com' include all columns  \n",
    "```python\n",
    "DataFrame.loc[DataFrame['email'].str.endswith(\"hotmail.com\")]\n",
    "```  \n",
    "\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T04:07:31.447071Z",
     "start_time": "2019-08-18T04:07:31.433221Z"
    }
   },
   "source": [
    "# Zipcode Methods  \n",
    "  \n",
    "```python\n",
    "!pip3 install uszipcode\n",
    "!pip3 install --upgrade uszipcode                # upgrade databases\n",
    "\n",
    "from uszipcode import SearchEngine\n",
    "search = SearchEngine(simple_zipcode=False)      # set simple_zipcode=False to use rich info database\n",
    "search = SearchEngine(simple_zipcode=True)       # False uses rich info database\n",
    "zipcode = search.by_zipcode(\"06916\")\n",
    "zipcode.to_json()                                # to json\n",
    "zipcode.to_dict()                                # to dict\n",
    "zip = zipcode.values()                           # to list\n",
    "zipcode\n",
    "```\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}